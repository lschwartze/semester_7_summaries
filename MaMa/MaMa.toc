\babel@toc {english}{}
\contentsline {section}{\numberline {1}Classification Learning}{3}{}%
\contentsline {subsection}{\numberline {1.1}vocabulary}{3}{}%
\contentsline {subsection}{\numberline {1.2}loss and error}{3}{}%
\contentsline {subsection}{\numberline {1.3}logistic regression}{4}{}%
\contentsline {subsection}{\numberline {1.4}training error and real life}{4}{}%
\contentsline {subsection}{\numberline {1.5}Quadratic classifier}{5}{}%
\contentsline {subsection}{\numberline {1.6}nearest neighbour classifier}{5}{}%
\contentsline {subsection}{\numberline {1.7}decision tree classifier}{5}{}%
\contentsline {subsection}{\numberline {1.8}loss functions}{6}{}%
\contentsline {subsection}{\numberline {1.9}A statistical model}{7}{}%
\contentsline {subsection}{\numberline {1.10}Bayes error and classifier}{8}{}%
\contentsline {section}{\numberline {2}PAC learning}{8}{}%
\contentsline {subsection}{\numberline {2.1}empirical risk minimisation}{8}{}%
\contentsline {subsection}{\numberline {2.2}error decomposition}{9}{}%
\contentsline {subsection}{\numberline {2.3}finitely many classifiers}{9}{}%
\contentsline {subsection}{\numberline {2.4}probably approximately correct (pac)}{9}{}%
\contentsline {subsection}{\numberline {2.5}VC-dimension}{10}{}%
\contentsline {subsection}{\numberline {2.6}Fundamental Theorem of PAC-learning}{11}{}%
\contentsline {subsection}{\numberline {2.7}VC-dimension of linear classifiers}{12}{}%
\contentsline {subsection}{\numberline {2.8}neural networks}{12}{}%
\contentsline {section}{\numberline {3}stochastic gradient descent}{13}{}%
\contentsline {subsection}{\numberline {3.1}convexity}{13}{}%
\contentsline {subsection}{\numberline {3.2}convex optimization}{14}{}%
\contentsline {subsection}{\numberline {3.3}Strong convexity}{15}{}%
\contentsline {subsection}{\numberline {3.4}gradient descent}{15}{}%
\contentsline {subsection}{\numberline {3.5}convergence of stochastic gradient descent}{16}{}%
\contentsline {section}{\numberline {4}neural networks}{16}{}%
\contentsline {subsection}{\numberline {4.1}back propagation}{16}{}%
\contentsline {subsection}{\numberline {4.2}Loss functions for neural networks}{18}{}%
\contentsline {subsection}{\numberline {4.3}local minima}{20}{}%
\contentsline {subsection}{\numberline {4.4}ReLU networks and piece-wise affine functions}{21}{}%
\contentsline {subsection}{\numberline {4.5}Universal approximators}{22}{}%
\contentsline {subsection}{\numberline {4.6}Deep neural networks vs. shallow neural networks}{23}{}%
\contentsline {subsection}{\numberline {4.7}Overconfident neural networks}{24}{}%
\contentsline {subsection}{\numberline {4.8}loss functions for binary classifications ($Y = \{-1,1\})$}{24}{}%
\contentsline {subsection}{\numberline {4.9}imbalanced classes}{25}{}%
\contentsline {subsection}{\numberline {4.10}fine-tuning after training}{26}{}%
\contentsline {section}{\numberline {5}ensemble learning}{28}{}%
\contentsline {subsection}{\numberline {5.1}wisdom of the crowd}{28}{}%
\contentsline {subsection}{\numberline {5.2}inequalties}{28}{}%
\contentsline {subsection}{\numberline {5.3}dependent classifiers}{28}{}%
\contentsline {subsection}{\numberline {5.4}random forests}{29}{}%
\contentsline {subsection}{\numberline {5.5}Adaboost}{30}{}%
