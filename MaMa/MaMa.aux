\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Classification Learning}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}vocabulary}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}loss and error}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}logistic regression}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}training error and real life}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Quadratic classifier}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}nearest neighbour classifier}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7}decision tree classifier}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8}loss functions}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9}A statistical model}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.10}Bayes error and classifier}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}PAC learning}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}empirical risk minimisation}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}error decomposition}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}finitely many classifiers}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}probably approximately correct (pac)}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}VC-dimension}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Fundamental Theorem of PAC-learning}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}VC-dimension of linear classifiers}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}neural networks}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}stochastic gradient descent}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}convexity}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}convex optimization}{14}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Strong convexity}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}gradient descent}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}convergence of stochastic gradient descent}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}neural networks}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}back propagation}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Loss functions for neural networks}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}local minima}{20}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}ReLU networks and piece-wise affine functions}{21}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Universal approximators}{22}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Deep neural networks vs. shallow neural networks}{23}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Overconfident neural networks}{24}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}loss functions for binary classifications ($Y = \{-1,1\})$}{24}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9}imbalanced classes}{25}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.10}fine-tuning after training}{26}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}ensemble learning}{28}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}wisdom of the crowd}{28}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}inequalties}{28}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}dependent classifiers}{28}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}random forests}{29}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Adaboost}{30}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}gradient boosting}{31}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}XGBoost}{31}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Autoencoders}{32}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}applications}{32}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}PCA}{33}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Kullback-Leibler divergence of normal distributions}{33}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Reconstruction loss of a variational autoencoder}{34}{}\protected@file@percent }
\gdef \@abspage@last{35}
